{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BlackSparrow-43/deep-rl-class/blob/main/My_Projects/Q-Learning/CartPole/Cartpole_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JJKMcx0Npqsu"
      },
      "outputs": [],
      "source": [
        "!pip install gym[all]  -q\n",
        "\n",
        "import time  \n",
        "import gym\n",
        "import numpy as np  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "KGYrOIOG8SaL"
      },
      "outputs": [],
      "source": [
        "from gym.envs.registration import register\n",
        "\n",
        "register(\n",
        "    id='CartPole-v1',\n",
        "    entry_point='gym.envs.classic_control:CartPoleEnv',\n",
        "    max_episode_steps=100000,\n",
        "    reward_threshold=195.0,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "iESfv9wvqSKD"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"CartPole-v1\")\n",
        "env.reset()\n",
        "obs_cart_vel=[]\n",
        "obs_pole_vel=[]\n",
        "for i in range(10):\n",
        "    action = env.action_space.sample()\n",
        "    obs,reward,done,info = env.step(action)\n",
        "    time.sleep(1)\n",
        "    obs_cart_vel.append(obs[1])\n",
        "    obs_pole_vel.append(obs[3])\n",
        "    if done == True:\n",
        "        break\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NzaUC2ZGqkaS"
      },
      "outputs": [],
      "source": [
        "obs_cart_vel_max = 5\n",
        "obs_cart_vel_min = -5\n",
        "obs_cart_pole_max = 5\n",
        "obs_cart_pole_min = -5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "r5UDo2qC1Vqa"
      },
      "outputs": [],
      "source": [
        "def bin_creation(no_of_bins):\n",
        "    bin_cart_pos = np.linspace(-2.4,2.4,no_of_bins)\n",
        "    bin_cart_vel = np.linspace(obs_cart_vel_min,obs_cart_vel_max,no_of_bins)\n",
        "    bin_pole_pos = np.linspace(-0.10472,0.10472,no_of_bins)\n",
        "    bin_pole_vel = np.linspace(obs_cart_pole_max,obs_cart_pole_min,no_of_bins)\n",
        "    bins = np.array([bin_cart_pos,bin_cart_vel,bin_pole_pos,bin_pole_vel])\n",
        "    return bins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "vXk0vFyM1Kra"
      },
      "outputs": [],
      "source": [
        "bins_no = 48\n",
        "bins_all = bin_creation(bins_no)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDljkWgZ1LPb",
        "outputId": "6073ec0b-4d79-4dbf-b004-7648798f5ee9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.40000000e+00, -2.29787234e+00, -2.19574468e+00,\n",
              "        -2.09361702e+00, -1.99148936e+00, -1.88936170e+00,\n",
              "        -1.78723404e+00, -1.68510638e+00, -1.58297872e+00,\n",
              "        -1.48085106e+00, -1.37872340e+00, -1.27659574e+00,\n",
              "        -1.17446809e+00, -1.07234043e+00, -9.70212766e-01,\n",
              "        -8.68085106e-01, -7.65957447e-01, -6.63829787e-01,\n",
              "        -5.61702128e-01, -4.59574468e-01, -3.57446809e-01,\n",
              "        -2.55319149e-01, -1.53191489e-01, -5.10638298e-02,\n",
              "         5.10638298e-02,  1.53191489e-01,  2.55319149e-01,\n",
              "         3.57446809e-01,  4.59574468e-01,  5.61702128e-01,\n",
              "         6.63829787e-01,  7.65957447e-01,  8.68085106e-01,\n",
              "         9.70212766e-01,  1.07234043e+00,  1.17446809e+00,\n",
              "         1.27659574e+00,  1.37872340e+00,  1.48085106e+00,\n",
              "         1.58297872e+00,  1.68510638e+00,  1.78723404e+00,\n",
              "         1.88936170e+00,  1.99148936e+00,  2.09361702e+00,\n",
              "         2.19574468e+00,  2.29787234e+00,  2.40000000e+00],\n",
              "       [-5.00000000e+00, -4.78723404e+00, -4.57446809e+00,\n",
              "        -4.36170213e+00, -4.14893617e+00, -3.93617021e+00,\n",
              "        -3.72340426e+00, -3.51063830e+00, -3.29787234e+00,\n",
              "        -3.08510638e+00, -2.87234043e+00, -2.65957447e+00,\n",
              "        -2.44680851e+00, -2.23404255e+00, -2.02127660e+00,\n",
              "        -1.80851064e+00, -1.59574468e+00, -1.38297872e+00,\n",
              "        -1.17021277e+00, -9.57446809e-01, -7.44680851e-01,\n",
              "        -5.31914894e-01, -3.19148936e-01, -1.06382979e-01,\n",
              "         1.06382979e-01,  3.19148936e-01,  5.31914894e-01,\n",
              "         7.44680851e-01,  9.57446809e-01,  1.17021277e+00,\n",
              "         1.38297872e+00,  1.59574468e+00,  1.80851064e+00,\n",
              "         2.02127660e+00,  2.23404255e+00,  2.44680851e+00,\n",
              "         2.65957447e+00,  2.87234043e+00,  3.08510638e+00,\n",
              "         3.29787234e+00,  3.51063830e+00,  3.72340426e+00,\n",
              "         3.93617021e+00,  4.14893617e+00,  4.36170213e+00,\n",
              "         4.57446809e+00,  4.78723404e+00,  5.00000000e+00],\n",
              "       [-1.04720000e-01, -1.00263830e-01, -9.58076596e-02,\n",
              "        -9.13514894e-02, -8.68953191e-02, -8.24391489e-02,\n",
              "        -7.79829787e-02, -7.35268085e-02, -6.90706383e-02,\n",
              "        -6.46144681e-02, -6.01582979e-02, -5.57021277e-02,\n",
              "        -5.12459574e-02, -4.67897872e-02, -4.23336170e-02,\n",
              "        -3.78774468e-02, -3.34212766e-02, -2.89651064e-02,\n",
              "        -2.45089362e-02, -2.00527660e-02, -1.55965957e-02,\n",
              "        -1.11404255e-02, -6.68425532e-03, -2.22808511e-03,\n",
              "         2.22808511e-03,  6.68425532e-03,  1.11404255e-02,\n",
              "         1.55965957e-02,  2.00527660e-02,  2.45089362e-02,\n",
              "         2.89651064e-02,  3.34212766e-02,  3.78774468e-02,\n",
              "         4.23336170e-02,  4.67897872e-02,  5.12459574e-02,\n",
              "         5.57021277e-02,  6.01582979e-02,  6.46144681e-02,\n",
              "         6.90706383e-02,  7.35268085e-02,  7.79829787e-02,\n",
              "         8.24391489e-02,  8.68953191e-02,  9.13514894e-02,\n",
              "         9.58076596e-02,  1.00263830e-01,  1.04720000e-01],\n",
              "       [ 5.00000000e+00,  4.78723404e+00,  4.57446809e+00,\n",
              "         4.36170213e+00,  4.14893617e+00,  3.93617021e+00,\n",
              "         3.72340426e+00,  3.51063830e+00,  3.29787234e+00,\n",
              "         3.08510638e+00,  2.87234043e+00,  2.65957447e+00,\n",
              "         2.44680851e+00,  2.23404255e+00,  2.02127660e+00,\n",
              "         1.80851064e+00,  1.59574468e+00,  1.38297872e+00,\n",
              "         1.17021277e+00,  9.57446809e-01,  7.44680851e-01,\n",
              "         5.31914894e-01,  3.19148936e-01,  1.06382979e-01,\n",
              "        -1.06382979e-01, -3.19148936e-01, -5.31914894e-01,\n",
              "        -7.44680851e-01, -9.57446809e-01, -1.17021277e+00,\n",
              "        -1.38297872e+00, -1.59574468e+00, -1.80851064e+00,\n",
              "        -2.02127660e+00, -2.23404255e+00, -2.44680851e+00,\n",
              "        -2.65957447e+00, -2.87234043e+00, -3.08510638e+00,\n",
              "        -3.29787234e+00, -3.51063830e+00, -3.72340426e+00,\n",
              "        -3.93617021e+00, -4.14893617e+00, -4.36170213e+00,\n",
              "        -4.57446809e+00, -4.78723404e+00, -5.00000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "bins_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2hdf7uZ81ON0"
      },
      "outputs": [],
      "source": [
        "def cont_to_dis(observation,bins):\n",
        "    digitised_obs = []\n",
        "    for i,obs in enumerate(observation):\n",
        "        digitised_obs.append((np.digitize(obs,bins_all[i]))-1)\n",
        "    return tuple(digitised_obs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "OW_z31D41UMm"
      },
      "outputs": [],
      "source": [
        "env = gym.make(\"CartPole-v1\")\n",
        "q_table_shape = (bins_no,bins_no,bins_no,bins_no,env.action_space.n)\n",
        "q_table = np.zeros(q_table_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48RMADZMh5o6",
        "outputId": "5c8fc8a2-4b40-4f0a-db1d-e1556708cee2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48, 48, 48, 48, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "q_table_shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "bnXduh4H2bPK"
      },
      "outputs": [],
      "source": [
        "epoch = 50000\n",
        "alpha = 0.8\n",
        "gamma = .95\n",
        "epsilon = 1\n",
        "max_epsilon = 1\n",
        "min_epsilon = .01\n",
        "epsilon_end = 10000\n",
        "decay_rate = .0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "FOyrvuVf1dum"
      },
      "outputs": [],
      "source": [
        "def epsilon_update_linear(epsilon,epoch):\n",
        "    if max_epsilon <= epoch <= epsilon_end:\n",
        "        epsilon -=decay_rate\n",
        "    return epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "al1UpiuL1hiu"
      },
      "outputs": [],
      "source": [
        "def epsilon_update_greedy(Gen):\n",
        "    return (min_epsilon+(max_epsilon-min_epsilon)*np.exp((-decay_rate)*Gen))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "kQSjnb_Y1lQ4"
      },
      "outputs": [],
      "source": [
        "def epsilon_greedy(epsilon,q_table,state):\n",
        "    random_no = np.random.random()\n",
        "    if random_no > epsilon:\n",
        "        action = np.argmax(q_table[state])\n",
        "        select=\"from_table\" \n",
        "    else:\n",
        "        action = env.action_space.sample()\n",
        "        select=\"random\"\n",
        "    return action,select"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "W3kcVw-x1my_"
      },
      "outputs": [],
      "source": [
        "def new_q_value_system(old_q_value,reward,next_q_value):\n",
        "    return old_q_value + alpha*(reward + gamma*(next_q_value - old_q_value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "uzTORgCs1rHH"
      },
      "outputs": [],
      "source": [
        "def reward_system(points,reward_obs,discreted_obs,done):\n",
        "    \n",
        "    angle = discreted_obs[2]\n",
        "    pos = discreted_obs[0]\n",
        "    reward_step = reward_ang = reward_pos = 0   \n",
        "    \n",
        "    if 1 <= angle <= 3:\n",
        "        reward_ang = -60\n",
        "    elif 3 <= angle <= 5:\n",
        "        reward_ang = -48\n",
        "    elif 5 <= angle <= 7:\n",
        "        reward_ang = -36\n",
        "    elif 7 <= angle <= 9:\n",
        "        reward_ang = -24\n",
        "    elif 9 <= angle <= 11:\n",
        "        reward_ang = -16\n",
        "    elif 11 <= angle <= 13:\n",
        "        reward_ang = -8\n",
        "    elif 13 <= angle <= 15:\n",
        "        reward_ang = -4\n",
        "    elif 15 <= angle <= 17:\n",
        "        reward_ang = -2\n",
        "    elif 17 <= angle <= 19:\n",
        "        reward_ang = 0\n",
        "    elif 19 <= angle <= 21:\n",
        "        reward_ang = 5\n",
        "    elif 21 <= angle <= 23:\n",
        "        reward_ang = 10\n",
        "    elif 23 <= angle <= 25:\n",
        "        reward_ang = 5\n",
        "    elif 25 <= angle <= 27:\n",
        "        reward_ang = 0\n",
        "    elif 27 <= angle <= 29:\n",
        "        reward_ang = -2\n",
        "    elif 29 <= angle <= 31:\n",
        "        reward_ang = -4\n",
        "    elif 31 <= angle <= 33:\n",
        "        reward_ang = -8\n",
        "    elif 33 <= angle <= 35:\n",
        "        reward_ang = -12\n",
        "    elif 35 <= angle <= 37:\n",
        "        reward_ang = -18\n",
        "    elif 37 <= angle <= 39:\n",
        "        reward_ang = -26\n",
        "    elif 39 <= angle <= 41:\n",
        "        reward_ang = -36\n",
        "    elif 41 <= angle <= 43:\n",
        "        reward_ang = -44\n",
        "    elif 43 <= angle <= 45:\n",
        "        reward_ang = -56\n",
        "    elif 45 <= angle <= 47:\n",
        "        reward_ang = -64\n",
        "    else:\n",
        "        reward_ang = -100\n",
        "\n",
        "\n",
        "    if 0 <= pos < 4:\n",
        "        reward_pos = -80\n",
        "    elif 4 <= pos < 8:\n",
        "        reward_pos = -40\n",
        "    elif 8 <= pos < 12:\n",
        "        reward_pos = -10\n",
        "    elif 12 <= pos < 16:\n",
        "        reward_pos = 0\n",
        "    elif 16 <= pos < 20:\n",
        "        reward_pos = 2\n",
        "    elif 20 <= pos < 24:\n",
        "        reward_pos = 5\n",
        "    elif 24 <= pos < 28:\n",
        "        reward_pos = 5\n",
        "    elif 28 <= pos < 32:\n",
        "        reward_pos = 2\n",
        "    elif 32 <= pos < 36:\n",
        "        reward_pos = 0\n",
        "    elif 36 <= pos < 40:\n",
        "        reward_pos = -10\n",
        "    elif 40 <= pos < 44:\n",
        "        reward_pos = -40\n",
        "    elif 44 <= pos < 48:\n",
        "        reward_pos = -80\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "    if done and points < 300:\n",
        "        reward_step = -300\n",
        "    \n",
        "    return reward_ang + reward_pos + reward_obs + 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "EqQfjmwYIUvY"
      },
      "outputs": [],
      "source": [
        "#q_table = np.load(\"Cartpole_q-table.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kh7uf1Yi2DIm"
      },
      "outputs": [],
      "source": [
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "rewards_interval = 0\n",
        "rewards = []\n",
        "log_interval = 1000\n",
        "gen = 0\n",
        "table_nos =0\n",
        "random_nos = 0\n",
        "total_rewards = 0\n",
        "total_steps = 0\n",
        "\n",
        "for Gen in range(epoch):\n",
        "    \n",
        "  state = env.reset()\n",
        "  discreted_obs = cont_to_dis(state,bins_all)\n",
        "  done = False\n",
        "  points = 0\n",
        "  steps = 0\n",
        "  \n",
        "  while not done:\n",
        "    steps += 1 \n",
        "    action,select = epsilon_greedy(epsilon,q_table,discreted_obs)\n",
        "    next_state,reward,done,info = env.step(action)\n",
        "    next_discreted_obs =  cont_to_dis(next_state,bins_all)\n",
        "      \n",
        "    old_q_value = q_table[discreted_obs+(action,)]\n",
        "    next_q_estim_value = np.max(q_table[next_discreted_obs])\n",
        "    reward = reward_system(points, reward, next_discreted_obs, done)\n",
        "    total_rewards += reward\n",
        "    new_q_value = new_q_value_system(old_q_value, reward, next_q_estim_value)\n",
        "      \n",
        "    q_table[discreted_obs+(action,)] = new_q_value\n",
        "      \n",
        "    discreted_obs = next_discreted_obs\n",
        "    points += 1\n",
        "    if select == \"from_table\":\n",
        "      table_nos+=1\n",
        "    elif select == \"random\":\n",
        "      random_nos+=1\n",
        "\n",
        "  total_steps += steps \n",
        "  epsilon = epsilon_update_greedy(Gen)\n",
        "  rewards.append(total_rewards)\n",
        "  rewards_interval = rewards_interval + total_rewards\n",
        "  \n",
        "  \n",
        "  if gen%log_interval == 0:\n",
        "    table_per = 100 *(table_nos / (table_nos + random_nos))\n",
        "    random_per = 100 *(random_nos / (table_nos + random_nos))\n",
        "    print(\"Gen=\"+str(Gen),\"table_choice=\"+str(int(table_per)),\"random_choice=\"+str(int(random_per)),\"Last_epsisode_steps=\"+str(steps),\"Interval_steps=\"+str(total_steps),\"total=\"+str(rewards_interval),end=\" \")\n",
        "    rewards_interval = 0\n",
        "    print(\"sum=\"+str(np.sum(rewards)),\"LearningRate=\"+str(epsilon))\n",
        "  gen = gen+1 \n",
        "print(\"Gen=\"+str(Gen),\"table_choice=\"+str(int(table_per)),\"random_choice=\"+str(int(random_per)),\"Last_epsisode_steps=\"+str(steps),\"Interval_steps=\"+str(total_steps),\"total=\"+str(rewards_interval),end=\" \")\n",
        "rewards_interval = 0\n",
        "print(\"sum=\"+str(np.sum(rewards)),\"LearningRate=\"+str(epsilon))\n",
        "env.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hCPeKnsHDMcq"
      },
      "outputs": [],
      "source": [
        "images = []  \n",
        "def show_render_4(env):\n",
        "  time.sleep(.1)\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBOJvP3Uh5pY"
      },
      "outputs": [],
      "source": [
        "\n",
        "rewards = 0\n",
        "points = 0 \n",
        "steps = 0\n",
        "observation = env.reset()\n",
        "show_render_4(env)\n",
        "while True:\n",
        "    steps += 1\n",
        "    show_render_4(env)\n",
        "    discreted_obs = cont_to_dis(observation,bins_all)  # get bins\n",
        "    action = np.argmax(q_table[discreted_obs])  # and chose action from the Q-Table\n",
        "    observation, reward, done, info = env.step(action) # Finally perform the action\n",
        "    points = points+1\n",
        "    temp=reward_system(points,reward,discreted_obs,done)\n",
        "    rewards += temp\n",
        "    print(\"total_reward=\",rewards)\n",
        "    if done:\n",
        "        break\n",
        "env.close()\n",
        "print(\"Steps=\"+str(steps),\"Reward=\"+str(points))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbSJRkt8D6eu"
      },
      "outputs": [],
      "source": [
        "print(\"Steps=\"+str(steps),\"Reward=\"+str(points))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpeE0yv9jdVJ"
      },
      "outputs": [],
      "source": [
        "!pip install imageio imageio_ffmpeg -q\n",
        "\n",
        "import imageio\n",
        "imageio.mimsave(\"cartpole.mp4\", [np.array(img) for i, img in enumerate(images)], fps=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zE4qw4MpDdid"
      },
      "outputs": [],
      "source": [
        "np.save(\"Cartpole_q-table\",q_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vovZBiCSh5pc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyglet==1.5.1 \n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "\n",
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhMWpoQ4By6W"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}